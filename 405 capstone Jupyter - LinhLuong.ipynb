{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Color:\n",
    "    RED = '\\033[91m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    BLUE = '\\033[94m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "def color_print(text, color):\n",
    "    print(f\"{color}{text}{Color.END}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Functional Requirements - Load Credit Card Database(SQL)\n",
    "def display_customer_table(json_file_path):\n",
    "    # pyspark code to read customer json file\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import initcap, lower,concat,lit,regexp_replace\n",
    "    try:\n",
    "    # Create a SparkSession\n",
    "        spark = SparkSession.builder.appName(\"Read_Customer_JSON\").getOrCreate()\n",
    "        # Read the JSON file into a DataFrame\n",
    "        df = spark.read.json(json_file_path)\n",
    "        df = df.withColumn(\"CUST_PHONE\", concat(lit(\"337\"), df[\"CUST_PHONE\"]))\n",
    "\n",
    "        formated_df = df.withColumn(\"ADDRESS\", concat(df[\"APT_NO\"], lit(\", \"), df[\"STREET_NAME\"])) \\\n",
    "                        .withColumn(\"CUST_PHONE\", regexp_replace(df[\"CUST_PHONE\"].cast(\"string\"), \"(\\\\d{3})(\\\\d{3})(\\\\d{4})\", \"($1)$2-$3\")) \\\n",
    "                        .withColumn(\"FIRST_NAME\", initcap(\"FIRST_NAME\")) \\\n",
    "                        .withColumn(\"MIDDLE_NAME\", lower(\"MIDDLE_NAME\")) \\\n",
    "                        .withColumn(\"LAST_NAME\", initcap(\"LAST_NAME\"))\n",
    "\n",
    "        # Show the DataFrame\n",
    "        formated_df.select(\"FIRST_NAME\", \"MIDDLE_NAME\", \"LAST_NAME\", \"SSN\", \"CREDIT_CARD_NO\", \"ADDRESS\", \"CUST_CITY\", \"CUST_STATE\", \"CUST_COUNTRY\", \"CUST_ZIP\", \"CUST_PHONE\", \"CUST_EMAIL\", \"LAST_UPDATED\").show(formated_df.count(),truncate=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        # Stop the SparkSession\n",
    "        spark.stop()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_branch_table():\n",
    "    # pyspark to read branch json file\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import initcap, lower,concat,lit,regexp_replace\n",
    "    try:\n",
    "    # Create a SparkSession\n",
    "        spark = SparkSession.builder.appName(\"Read_branch_JSON\").getOrCreate()\n",
    "\n",
    "        # Specify the path to the JSON file\n",
    "        json_file_path = r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_branch.json\"\n",
    "\n",
    "        # Read the JSON file into a DataFrame\n",
    "        df = spark.read.json(json_file_path)\n",
    "        formated_df = df.withColumn(\"BRANCH_PHONE\", regexp_replace(df[\"BRANCH_PHONE\"].cast(\"string\"), \"(\\\\d{3})(\\\\d{3})(\\\\d{4})\", \"($1)$2-$3\"))\n",
    "     \n",
    "    # Show the DataFrame\n",
    "        formated_df.select(\"BRANCH_CODE\",\"BRANCH_NAME\",\"BRANCH_STREET\",\"BRANCH_CITY\",\"BRANCH_STATE\",\"BRANCH_ZIP\",\"BRANCH_PHONE\",\"LAST_UPDATED\").show(df.count(),truncate=False)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    finally:\n",
    "    # Stop the SparkSession\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_credit_table():\n",
    "    # pyspark to read credit json file\n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    # Create a SparkSession\n",
    "    spark = SparkSession.builder.appName(\"Read_credit_JSON\").getOrCreate()\n",
    "\n",
    "    # Specify the path to the JSON file\n",
    "    json_file_path = r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\"\n",
    "\n",
    "    # Read the JSON file into a DataFrame\n",
    "    df = spark.read.json(json_file_path)\n",
    "\n",
    "    try: \n",
    "    # Show the DataFrame\n",
    "        df.select(\"TRANSACTION_ID\",\"DAY\",\"MONTH\",\"YEAR\",\"CREDIT_CARD_NO\",\"CUST_SSN\",\"BRANCH_CODE\",\"TRANSACTION_TYPE\",\"TRANSACTION_VALUE\").show(df.count(),truncate=False)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    # Stop the SparkSession\n",
    "    finally:\n",
    "        spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Data Loading into Database\n",
    "def create_database_in_mysql():\n",
    "    import mysql.connector\n",
    "    import json\n",
    "    try:\n",
    "        conn = mysql.connector.connect(\n",
    "            host=\"localhost\",\n",
    "            user=\"root\",\n",
    "            password=\"password\",\n",
    "        )\n",
    "    \n",
    "    # Execute a SQL query to create the database\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"CREATE DATABASE IF NOT EXISTS `creditcard_capstone`\")\n",
    "        conn.commit()\n",
    "        print(\"Database created successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating database: {e}\")\n",
    "    finally:\n",
    "    # Close the Spark session\n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_in_mysql():\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import initcap, lower,concat,lit,regexp_replace\n",
    "    try:\n",
    "    # Create a Spark session\n",
    "        spark = SparkSession.builder.appName(\"CreateTableInMySQL\").config(\"spark.jars\", r\"E:\\soft\\Spark\\spark-3.5.0-bin-hadoop3\\jars\\mysql-connector-j-8.3.0.jar\").getOrCreate()\n",
    "\n",
    "        # Define the JDBC URL for the MySQL database\n",
    "        jdbc_url = \"jdbc:mysql://localhost:3306/creditcard_capstone\"\n",
    "\n",
    "        df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_custmer.json\")\n",
    "        df2 = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_branch.json\")\n",
    "        df3 = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\")\n",
    "        df = df.withColumn(\"CUST_PHONE\", concat(lit(\"337\"), df[\"CUST_PHONE\"]))\n",
    "        df = df.withColumn(\"CUST_PHONE\", regexp_replace(df[\"CUST_PHONE\"].cast(\"string\"), \"(\\\\d{3})(\\\\d{3})(\\\\d{4})\", \"($1)$2-$3\")) \\\n",
    "                .withColumn(\"FIRST_NAME\", initcap(\"FIRST_NAME\")) \\\n",
    "                .withColumn(\"MIDDLE_NAME\", lower(\"MIDDLE_NAME\")) \\\n",
    "                .withColumn(\"LAST_NAME\", initcap(\"LAST_NAME\"))        \n",
    "                \n",
    "        df2 = df2.withColumn(\"BRANCH_PHONE\", regexp_replace(df2[\"BRANCH_PHONE\"].cast(\"string\"), \"(\\\\d{3})(\\\\d{3})(\\\\d{4})\", \"($1)$2-$3\"))\n",
    "\n",
    "        # Write the DataFrame to the MySQL table \n",
    "        df.write.format(\"jdbc\") \\\n",
    "        .option(\"url\", jdbc_url) \\\n",
    "        .option(\"dbtable\", \"CDW_SAPP_CUSTOMER\") \\\n",
    "        .option(\"user\", \"root\") \\\n",
    "        .option(\"password\", \"password\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "        \n",
    "        \n",
    "        df2.write.format(\"jdbc\") \\\n",
    "        .option(\"url\", jdbc_url) \\\n",
    "        .option(\"dbtable\", \"CDW_SAPP_BRANCH\") \\\n",
    "        .option(\"user\", \"root\") \\\n",
    "        .option(\"password\", \"password\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "        \n",
    "        df3.write.format(\"jdbc\") \\\n",
    "        .option(\"url\", jdbc_url) \\\n",
    "        .option(\"dbtable\", \"CDW_SAPP_CREDIT_CARD\") \\\n",
    "        .option(\"user\", \"root\") \\\n",
    "        .option(\"password\", \"password\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "        \n",
    "    finally:\n",
    "    # Close the Spark session\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to modify the tables and set up relationship between table and primary key\n",
    "def modify_tables():\n",
    "    import mysql.connector\n",
    "    import json\n",
    "    try:\n",
    "        conn = mysql.connector.connect(\n",
    "            host=\"localhost\",\n",
    "            user=\"root\",\n",
    "            password=\"password\",\n",
    "            database=\"creditcard_capstone\"\n",
    "        )\n",
    "    \n",
    "        # Execute a SQL query\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "                        ALTER TABLE cdw_sapp_customer \n",
    "                        MODIFY COLUMN CREDIT_CARD_NO VARCHAR(255),\n",
    "                        ADD PRIMARY KEY (SSN),\n",
    "                        ADD INDEX credit_card_index (CREDIT_CARD_NO);\n",
    "                        \"\"\")\n",
    "        conn.commit()\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "                       ALTER TABLE cdw_sapp_branch\n",
    "                       ADD PRIMARY KEY (BRANCH_CODE)\n",
    "                       \"\"\")\n",
    "        conn.commit()\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "                       ALTER TABLE cdw_sapp_credit_card\n",
    "                       MODIFY COLUMN CREDIT_CARD_NO VARCHAR(255),\n",
    "                       ADD PRIMARY KEY (TRANSACTION_ID),\n",
    "                       ADD CONSTRAINT `branch_fk` FOREIGN KEY (`BRANCH_CODE`) REFERENCES `CDW_SAPP_BRANCH` (`BRANCH_CODE`),\n",
    "                       ADD CONSTRAINT `credit_card_fk` FOREIGN KEY (CREDIT_CARD_NO) REFERENCES `CDW_SAPP_CUSTOMER`(CREDIT_CARD_NO)\n",
    "        \"\"\")\n",
    "        conn.commit()    \n",
    "        \n",
    "\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "    # Close the session\n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Transaction Details Module\n",
    "# Prompt the user for a zip code, provide contextual cues for valid input, and verify it is in the correct format.\n",
    "# 1 a. Prompt the user for a zip code\n",
    "def prompt_user_zipcode():\n",
    "    try:\n",
    "        while True:\n",
    "            zipcode = input(\"Enter your zipcode (Enter 5-digit number): \")\n",
    "            if len(zipcode) == 5 and zipcode.isdigit():\n",
    "                return int(zipcode)\n",
    "            else:\n",
    "                print(\"Invalid zipcode. Please enter a 5-digit number.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# b. Prompt the user for a month , year\n",
    "def prompt_user_month():\n",
    "    try:\n",
    "        while True:\n",
    "            month_input = input(\"Enter your month (Enter number 1 - 12): \")\n",
    "            if month_input.isdigit():\n",
    "                if 1 <= int(month_input) <= 12:\n",
    "                    return int(month_input)\n",
    "                else:\n",
    "                    print(\"Invalid month. Please enter a number between 1 and 12.\")\n",
    "            else:\n",
    "                print(\"Invalid Input. Please enter a number between 1 and 12.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "def prompt_user_year():\n",
    "    try:\n",
    "        while True:\n",
    "            year_input = input(\"Enter your year (Enter 4-digit number): \")\n",
    "            if len(year_input) == 4 and year_input.isdigit():\n",
    "                return int(year_input)\n",
    "            else:\n",
    "                print(\"Invalid year. Please enter a 4-digit number.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Query the data using Spark SQL base on user input zipcode, month, year\n",
    "def customer_transaction_details(zipcode, month, year):\n",
    "    from pyspark.sql import SparkSession\n",
    "    import json\n",
    "    # Create a Spark session\n",
    "    try:\n",
    "        spark = SparkSession.builder.appName(\"QueryTransactionData\").getOrCreate()\n",
    "\n",
    "        # Load JSON data into DataFrames\n",
    "        branch_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_branch.json\")\n",
    "        transaction_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\")\n",
    "\n",
    "        # Load data from MySQL database using JDBC\n",
    "        jdbc_url = \"jdbc:mysql://localhost:3306/creditcard_capstone\"\n",
    "        properties = {\n",
    "            \"user\": \"root\",\n",
    "            \"password\": \"password\",\n",
    "            \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "        }\n",
    "\n",
    "        # Query the data using Spark SQL\n",
    "        branch_df.createOrReplaceTempView(\"branch\")\n",
    "        transaction_df.createOrReplaceTempView(\"transaction\")\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT branch.BRANCH_CODE, branch.BRANCH_ZIP, transaction.DAY, transaction.MONTH, transaction.YEAR, branch.BRANCH_NAME, branch.BRANCH_STREET, branch.BRANCH_CITY, branch.BRANCH_STATE, branch.BRANCH_PHONE, transaction.CREDIT_CARD_NO, transaction.CUST_SSN, transaction.TRANSACTION_ID, transaction.TRANSACTION_TYPE, transaction.TRANSACTION_VALUE, branch.LAST_UPDATED\n",
    "            FROM branch \n",
    "            JOIN transaction \n",
    "            Using (BRANCH_CODE) \n",
    "            WHERE branch.BRANCH_ZIP = {zipcode} \n",
    "            AND transaction.MONTH = {month} \n",
    "            AND transaction.YEAR = {year}\n",
    "        \"\"\"\n",
    "        result_df = spark.sql(query)\n",
    "\n",
    "        # Show the result DataFrame\n",
    "        result_df.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    finally:  \n",
    "        # Stop the Spark session\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. Sort the transaction by day\n",
    "def sort_transaction_by_day():\n",
    "    # pyspark to read credit json file\n",
    "    from pyspark.sql import SparkSession\n",
    "    # Create a SparkSession\n",
    "    spark = SparkSession.builder.appName(\"Read_credit_JSON\").getOrCreate()\n",
    "\n",
    "    # Specify the path to the JSON file\n",
    "    json_file_path = r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\"\n",
    "\n",
    "    # Read the JSON file into a DataFrame\n",
    "    df = spark.read.json(json_file_path)\n",
    "\n",
    "    try: \n",
    "    # Show the DataFrame\n",
    "        df.select(\"TRANSACTION_ID\",\"DAY\",\"MONTH\",\"YEAR\",\"CREDIT_CARD_NO\",\"CUST_SSN\",\"BRANCH_CODE\",\"TRANSACTION_TYPE\",\"TRANSACTION_VALUE\").orderBy(\"DAY\", ascending=False).show(df.count(),truncate=False)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    finally:\n",
    "    # Stop the SparkSession\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Use to display number and value of transaction type\n",
    "def transaction_number_value(type):\n",
    "    from pyspark.sql import SparkSession\n",
    "    # Create a SparkSession\n",
    "    spark = SparkSession.builder.appName(\"trasaction_JSON\").getOrCreate()\n",
    "    # Specify the path to the JSON file\n",
    "    json_file_path = r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\"\n",
    "    # Read the JSON file into a DataFrame\n",
    "    df = spark.read.json(json_file_path)\n",
    "\n",
    "    try: \n",
    "    # Show the DataFrame\n",
    "        df.createOrReplaceTempView(\"transaction\")\n",
    "        spark.sql(f\"\"\"SELECT TRANSACTION_TYPE, count(TRANSACTION_TYPE) as Number, round(Sum(TRANSACTION_VALUE),2) as Total \n",
    "                    FROM transaction \n",
    "                    Group By TRANSACTION_TYPE \n",
    "                    HAVING TRANSACTION_TYPE = '{type}'\"\"\").show(df.count(),truncate=False)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    finally:\n",
    "    # Stop the SparkSession\n",
    "        spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_user_type():\n",
    "    try:\n",
    "        while True:\n",
    "            type = input(\"Enter Transaction Type (Healthcare, Automotive, etc.): \")\n",
    "            if type.isalpha():\n",
    "                return type\n",
    "            else:\n",
    "                print(\"Invalid input. Please enter string only.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Use to display number and total value of transaction branch by given state\n",
    "def transaction_branch_number_value_state(state):\n",
    "    from pyspark.sql import SparkSession\n",
    "    try:\n",
    "    # Create a SparkSession\n",
    "        spark = SparkSession.builder.appName(\"trasaction_JSON\").getOrCreate()\n",
    "        # Read the JSON file into a DataFrame\n",
    "        df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\")\n",
    "        branch_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_branch.json\")\n",
    "\n",
    "        \n",
    "        # Show the DataFrame\n",
    "        df.createOrReplaceTempView(\"transaction\")\n",
    "        branch_df.createOrReplaceTempView(\"branch\")\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT branch.BRANCH_STATE, count(TRANSACTION_TYPE) as Number, round(Sum(TRANSACTION_VALUE),2) as Total_value_transactions\n",
    "            FROM branch \n",
    "            JOIN transaction \n",
    "            Using (BRANCH_CODE)\n",
    "            WHERE branch.BRANCH_STATE = '{state}'\n",
    "            Group By branch.BRANCH_STATE\n",
    "        \"\"\"\n",
    "        \n",
    "        result_df = spark.sql(query)\n",
    "        # Show the result DataFrame\n",
    "        result_df.show()\n",
    "        \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    finally:\n",
    "    # Stop the SparkSession\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_user_state():\n",
    "    try:\n",
    "        while True:\n",
    "            state = input(\"Enter State (LA, CA, etc.): \")\n",
    "            if state.isalpha():\n",
    "                if len(state) == 2:\n",
    "                    return state.upper()\n",
    "                else:\n",
    "                    print(\"Invalid input. Please enter 2-letters for the state only.\")\n",
    "            else:\n",
    "                print(\"Invalid input. Please enter string only.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Customer Details Module\n",
    "# 1 Check existing account details of customer\n",
    "def check_cust_detail(SSN):\n",
    "    from pyspark.sql import SparkSession\n",
    "    try:\n",
    "    # Create a SparkSession\n",
    "        spark = SparkSession.builder.appName(\"check customer detail\").getOrCreate()\n",
    "        # Read the JSON file into a DataFrame\n",
    "        credit_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\")\n",
    "        customer_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_custmer.json\")\n",
    "        branch_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_branch.json\")\n",
    "\n",
    "        \n",
    "        # Show the DataFrame\n",
    "        credit_df.createOrReplaceTempView(\"credit\")\n",
    "        customer_df.createOrReplaceTempView(\"customer\")\n",
    "        branch_df.createOrReplaceTempView(\"branch\")\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT customer.SSN, \n",
    "            customer.FIRST_NAME, \n",
    "            customer.MIDDLE_NAME, \n",
    "            customer.LAST_NAME, \n",
    "            customer.CREDIT_CARD_NO, \n",
    "            customer.APT_NO, \n",
    "            customer.STREET_NAME, \n",
    "            customer.CUST_CITY, \n",
    "            customer.CUST_STATE, \n",
    "            customer.CUST_ZIP, \n",
    "            customer.CUST_COUNTRY, \n",
    "            customer.CUST_EMAIL, \n",
    "            customer.CUST_PHONE,\n",
    "            branch.BRANCH_NAME,\n",
    "            credit.DAY,\n",
    "            credit.MONTH,\n",
    "            credit.YEAR,\n",
    "            credit.TRANSACTION_TYPE,\n",
    "            credit.TRANSACTION_VALUE\n",
    "            FROM customer\n",
    "            JOIN credit\n",
    "            Using (CREDIT_CARD_NO)\n",
    "            JOIN branch\n",
    "            Using (BRANCH_CODE)\n",
    "            WHERE RIGHT(customer.SSN, 4) = '{SSN}'\n",
    "            ORDER BY credit.YEAR, credit.MONTH, credit.DAY\n",
    "            \"\"\"\n",
    "            \n",
    "        result_df = spark.sql(query)\n",
    "        # Show the result DataFrame\n",
    "        result_df.show()\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    finally:\n",
    "    # Stop the SparkSession\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_user_SSN():\n",
    "    try:\n",
    "        while True:\n",
    "            SSN = input(\"Enter Customer last 4 SSN: \")\n",
    "            if SSN.isnumeric():\n",
    "                if len(SSN) == 4:\n",
    "                    return SSN\n",
    "                else:\n",
    "                    print(\"Invalid input. Please enter 4-digit number only.\")\n",
    "            else:\n",
    "                print(\"Invalid input. Please enter number only.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cust_SSN(SSN):\n",
    "    import json\n",
    "    try:\n",
    "        with open(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_custmer.json\") as f:\n",
    "            for line in f:\n",
    "                customer_data = json.loads(line)\n",
    "                if str(customer_data[\"SSN\"])[-4:] == str(SSN):\n",
    "                    return True\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_cust_copy():\n",
    "    import mysql.connector\n",
    "    import json\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "    spark = SparkSession.builder.appName(\"Write_JSON_File\").getOrCreate()\n",
    "    schema = StructType([\n",
    "    StructField(\"FIRST_NAME\", StringType(), True),\n",
    "    StructField(\"MIDDLE_NAME\", StringType(), True),\n",
    "    StructField(\"LAST_NAME\", StringType(), True),\n",
    "    StructField(\"SSN\", IntegerType(), True),\n",
    "    StructField(\"CREDIT_CARD_NO\", StringType(), True),\n",
    "    StructField(\"APT_NO\", StringType(), True),\n",
    "    StructField(\"STREET_NAME\", StringType(), True),\n",
    "    StructField(\"CUST_CITY\", StringType(), True),\n",
    "    StructField(\"CUST_STATE\", StringType(), True),\n",
    "    StructField(\"CUST_COUNTRY\", StringType(), True),\n",
    "    StructField(\"CUST_ZIP\", StringType(), True),\n",
    "    StructField(\"CUST_PHONE\", StringType(), True),\n",
    "    StructField(\"CUST_EMAIL\", StringType(), True),\n",
    "    StructField(\"LAST_UPDATED\", StringType(), True),\n",
    "    ])\n",
    "    try:     \n",
    "        conn = mysql.connector.connect(\n",
    "            host=\"localhost\",\n",
    "            user=\"root\",\n",
    "            password=\"password\",\n",
    "            database=\"creditcard_capstone\"\n",
    "        )\n",
    "          \n",
    "        query = f\"\"\"\n",
    "                SELECT \n",
    "                FIRST_NAME,\n",
    "                MIDDLE_NAME, \n",
    "                LAST_NAME, \n",
    "                SSN, \n",
    "                CREDIT_CARD_NO, \n",
    "                APT_NO,\n",
    "                STREET_NAME, \n",
    "                CUST_CITY, \n",
    "                CUST_STATE, \n",
    "                CUST_COUNTRY, \n",
    "                CUST_ZIP, \n",
    "                CUST_PHONE, \n",
    "                CUST_EMAIL, \n",
    "                LAST_UPDATED \n",
    "                FROM cdw_sapp_customer\"\"\"\n",
    "                \n",
    "        cursor = conn.cursor()        \n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        \n",
    "        data = []\n",
    "        for row in result:\n",
    "            row_dict = [row[0],row[1],row[2],row[3],row[4],row[5],row[6],row[7],row[8],row[9],row[10],row[11],row[12],row[13]]\n",
    "            data.append(row_dict)\n",
    "        df = spark.createDataFrame(data, schema=schema)\n",
    "        # Write the DataFrame to a JSON file\n",
    "        df.write.mode(\"overwrite\").json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_custmer_copy.json\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Modify existing account details of a customer\n",
    "def modify_cust_detail(column, value, SSN):\n",
    "    import mysql.connector\n",
    "    import json\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "    spark = SparkSession.builder.appName(\"Write_JSON_File\").getOrCreate()\n",
    "    schema = StructType([\n",
    "    StructField(\"FIRST_NAME\", StringType(), True),\n",
    "    StructField(\"MIDDLE_NAME\", StringType(), True),\n",
    "    StructField(\"LAST_NAME\", StringType(), True),\n",
    "    StructField(\"SSN\", IntegerType(), True),\n",
    "    StructField(\"CREDIT_CARD_NO\", StringType(), True),\n",
    "    StructField(\"APT_NO\", StringType(), True),\n",
    "    StructField(\"STREET_NAME\", StringType(), True),\n",
    "    StructField(\"CUST_CITY\", StringType(), True),\n",
    "    StructField(\"CUST_STATE\", StringType(), True),\n",
    "    StructField(\"CUST_COUNTRY\", StringType(), True),\n",
    "    StructField(\"CUST_ZIP\", StringType(), True),\n",
    "    StructField(\"CUST_PHONE\", StringType(), True),\n",
    "    StructField(\"CUST_EMAIL\", StringType(), True),\n",
    "    StructField(\"LAST_UPDATED\", StringType(), True),\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        conn = mysql.connector.connect(\n",
    "            host=\"localhost\",\n",
    "            user=\"root\",\n",
    "            password=\"password\",\n",
    "            database=\"creditcard_capstone\"\n",
    "        )\n",
    "    \n",
    "        # Execute a SQL query\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        if check_cust_SSN(SSN):\n",
    "            cursor.execute(f\"\"\"\n",
    "                            UPDATE cdw_sapp_customer\n",
    "                            SET {column} = '{value}'\n",
    "                            WHERE RIGHT(SSN, 4) = '{SSN}';\n",
    "                        \"\"\")\n",
    "            conn.commit()\n",
    "        else:\n",
    "            print(\"Invalid Customer SSN.\")\n",
    "        \n",
    "        query = f\"\"\"\n",
    "                SELECT \n",
    "                FIRST_NAME,\n",
    "                MIDDLE_NAME, \n",
    "                LAST_NAME, \n",
    "                SSN, \n",
    "                CREDIT_CARD_NO, \n",
    "                APT_NO,\n",
    "                STREET_NAME, \n",
    "                CUST_CITY, \n",
    "                CUST_STATE, \n",
    "                CUST_COUNTRY, \n",
    "                CUST_ZIP, \n",
    "                CUST_PHONE, \n",
    "                CUST_EMAIL, \n",
    "                LAST_UPDATED \n",
    "                FROM cdw_sapp_customer\"\"\"\n",
    "                \n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        \n",
    "        data = []\n",
    "        for row in result:\n",
    "            row_dict = [row[0],row[1],row[2],row[3],row[4],row[5],row[6],row[7],row[8],row[9],row[10],row[11],row[12],row[13]]\n",
    "            data.append(row_dict)\n",
    "        df = spark.createDataFrame(data, schema=schema)\n",
    "        # Write the DataFrame to a JSON file\n",
    "        df.write.mode(\"overwrite\").json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_custmer_copy.json\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_user_column():\n",
    "    try:\n",
    "        col = [\"FIRST_NAME\", \"MIDDLE_NAME\", \"LAST_NAME\", \"CREDIT_CARD_NO\", \"CUST_CITY\", \"CUST_STATE\", \"CUST_COUNTRY\", \"CUST_ZIP\", \"CUST_PHONE\", \"CUST_EMAIL\", \"APT NO\", \"STREET_NAME\", \"SSN\"]\n",
    "        color_print(\"Columns list: \", Color.GREEN)\n",
    "        print(col)\n",
    "        while True:\n",
    "            column = input(\"Enter column name to update: \")\n",
    "            if column in col:\n",
    "                return column\n",
    "            else:\n",
    "                print(\"Invalid input. Please enter a valid column name.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "def prompt_user_value():\n",
    "    try:\n",
    "        while True:\n",
    "            value = input(\"Enter new value: \")\n",
    "            if value.isnumeric():\n",
    "                return int(value)\n",
    "            else:\n",
    "                return value\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Generate monthly bill for a credit card number for a given month and year\n",
    "\n",
    "def check_credit_card(credit_card_no):\n",
    "    import json\n",
    "    try:\n",
    "        with open(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\") as f:\n",
    "            for line in f:\n",
    "                credit_data = json.loads(line)\n",
    "                if str(credit_data[\"CREDIT_CARD_NO\"]) == str(credit_card_no):\n",
    "                    return True\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_monthly_bill(credit_card_no, month, year):\n",
    "    import json\n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    spark = SparkSession.builder.appName(\"trasaction_JSON\").getOrCreate()\n",
    "    try:\n",
    "        if check_credit_card(credit_card_no):\n",
    "            bill_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\")\n",
    "            bill_df.createOrReplaceTempView(\"bill\")\n",
    "            \n",
    "            query = f\"\"\"\n",
    "                SELECT  CREDIT_CARD_NO, \n",
    "                        MONTH,\n",
    "                        YEAR,\n",
    "                        TRANSACTION_TYPE, \n",
    "                        TRANSACTION_VALUE\n",
    "                        FROM bill\n",
    "                        WHERE CREDIT_CARD_NO = {credit_card_no} \n",
    "                        AND MONTH = {month} \n",
    "                        AND YEAR = {year}              \n",
    "                        ORDER BY YEAR, MONTH, TRANSACTION_TYPE\n",
    "                \"\"\"\n",
    "            bill_df = spark.sql(query)\n",
    "            bill_df.show()\n",
    "            \n",
    "            total = f\"\"\"SELECT  round(sum(TRANSACTION_VALUE),2) as TOTAL_TRANSACTION \n",
    "                                FROM bill \n",
    "                                WHERE CREDIT_CARD_NO = {credit_card_no} \n",
    "                                AND MONTH = {month} \n",
    "                                AND YEAR = {year}\n",
    "                                \n",
    "                                \"\"\"\n",
    "            bill_df = spark.sql(total)\n",
    "            bill_df.show()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_user_credit_card():\n",
    "    try:\n",
    "        while True:\n",
    "            credit_card_no = input(\"Enter your credit card number (16 digits): \")\n",
    "            if len(credit_card_no) == 16 and credit_card_no.isdigit():\n",
    "                return str(credit_card_no)\n",
    "            else:\n",
    "                print(\"Invalid credit card number. Please enter a 16-digit number.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_transactions_between_dates(credit_card_no, start_day, start_month, start_year, end_day, end_month, end_year):\n",
    "    import json\n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    spark = SparkSession.builder.appName(\"transactions_JSON\").getOrCreate()\n",
    "    \n",
    "    try:\n",
    "        if check_credit_card(credit_card_no):\n",
    "            transaction_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\")\n",
    "            transaction_df.createOrReplaceTempView(\"transactions\")\n",
    "            \n",
    "            query = f\"\"\"\n",
    "                SELECT  CREDIT_CARD_NO, \n",
    "                        DAY,\n",
    "                        MONTH,\n",
    "                        YEAR,\n",
    "                        TRANSACTION_TYPE, \n",
    "                        TRANSACTION_VALUE\n",
    "                FROM transactions\n",
    "                WHERE CREDIT_CARD_NO = '{credit_card_no}' \n",
    "                AND DAY >= {start_day}\n",
    "                AND DAY <= {end_day}\n",
    "                AND MONTH >= {start_month}\n",
    "                AND MONTH <= {end_month}\n",
    "                AND YEAR >= {start_year}\n",
    "                AND YEAR <= {end_year}\n",
    "                ORDER BY YEAR DESC, MONTH DESC, DAY DESC\n",
    "            \"\"\"\n",
    "            result_df = spark.sql(query)\n",
    "            result_df.show(result_df.count(), False)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_user_day():\n",
    "    try:\n",
    "        while True:\n",
    "            day_input = input(\"Enter your day (1-31): \")\n",
    "            if len(day_input) == 1 or len(day_input) == 2 and day_input.isdigit():\n",
    "                if int(day_input) >= 1 and int(day_input) <= 31:\n",
    "                    return int(day_input)\n",
    "                else:\n",
    "                    print(\"Invalid day. Please enter a number between 1 and 31.\")\n",
    "            else:\n",
    "                print(\"Invalid day. Please enter a number between 1 and 31.\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_menu():\n",
    "    color_print(\"=====Welcome to the CDW SAPP Credit Card Transaction Management System!=====\", Color.BLUE)\n",
    "    color_print(\"What do you want to do? Please choose an option: \", Color.GREEN)\n",
    "    color_print(\"1. Display Customer Information.\", Color.RED)\n",
    "    color_print(\"2. Display Branch Information.\", Color.RED)\n",
    "    color_print(\"3. Display Credit Card and Transaction Information.\", Color.RED)\n",
    "    color_print(\"4. Retrieve customer's transaction in specified zip code for a given month and year.\", Color.RED)\n",
    "    color_print(\"5. Sort the transactions by day in descending order.\", Color.RED)\n",
    "    color_print(\"6. Display number and total values of transactions for a given type.\", Color.RED)\n",
    "    color_print(\"7. Display the total number and total values of transactions for branches in a given state.\", Color.RED)\n",
    "    color_print(\"8. Check existing account details of a customer.\", Color.RED)\n",
    "    color_print(\"9. Modify existing account details of a customer.\", Color.RED)\n",
    "    color_print(\"10. Generate monthly bill.\", Color.RED)\n",
    "    color_print(\"11. Display transactions between dates.\", Color.RED)\n",
    "    color_print(\"12. Exit.\", Color.YELLOW)\n",
    "    color_print(\"==========================================================================\", Color.BLUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_user_choice():\n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Enter your choice: \"))\n",
    "            if 1 <= choice <= 12:\n",
    "                return choice\n",
    "            else:\n",
    "                print(\"Invalid choice. Please enter a number between 1 and 10.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_option(option):\n",
    "    import sys\n",
    "    if option == 1:\n",
    "        color_print(\"1. Display Customer Information.\", Color.RED)\n",
    "        display_customer_table()\n",
    "    \n",
    "    elif option == 2:\n",
    "        color_print(\"2. Display Branch Information.\", Color.RED)\n",
    "        display_branch_table()\n",
    "        \n",
    "    elif option == 3:\n",
    "        color_print(\"3. Display Credit Card and Transaction Information.\", Color.RED)\n",
    "        display_credit_table()\n",
    "        \n",
    "    elif option == 4:\n",
    "        color_print(\"4. Retrieve customer's transaction in specified zip code for a given month and year\", Color.RED)\n",
    "        customer_transaction_details(prompt_user_zipcode(), prompt_user_month(), prompt_user_year())\n",
    "        \n",
    "    elif option == 5:\n",
    "        color_print(\"5. Sort the transactions by day in descending order.\", Color.RED)\n",
    "        sort_transaction_by_day()\n",
    "        \n",
    "    elif option == 6:\n",
    "        color_print(\"6. Display number and total values of transactions for a given type.\", Color.RED)\n",
    "        transaction_number_value(prompt_user_type())\n",
    "        \n",
    "    elif option == 7:\n",
    "        color_print(\"7. Display the total number and total values of transactions for branches in a given state.\", Color.RED)\n",
    "        transaction_branch_number_value_state(prompt_user_state())\n",
    "        \n",
    "    elif option == 8:\n",
    "        color_print(\"8. Check existing account details of a customer.\", Color.RED)\n",
    "        check_cust_detail(prompt_user_SSN())\n",
    "        \n",
    "    elif option == 9:\n",
    "        color_print(\"9. Modify existing account details of a customer.\", Color.RED)\n",
    "        modify_cust_detail(prompt_user_column(), prompt_user_value(), prompt_user_SSN())\n",
    "        \n",
    "    elif option == 10:\n",
    "        color_print(\"Generate monthly bill.\", Color.RED)\n",
    "        generate_monthly_bill(prompt_user_credit_card(), prompt_user_month(), prompt_user_year())\n",
    "        \n",
    "    elif option == 11:\n",
    "        color_print(\"Display transactions between dates.\", Color.RED)\n",
    "        color_print(\"Please enter the start date: \", Color.GREEN)\n",
    "        start_day = prompt_user_day()\n",
    "        color_print(\"Please enter the start month: \", Color.GREEN)\n",
    "        start_month = prompt_user_month()\n",
    "        color_print(\"Please enter the start year: \", Color.GREEN)\n",
    "        start_year = prompt_user_year()\n",
    "        color_print(\"Please enter the end day: \", Color.GREEN)\n",
    "        end_day = prompt_user_day()\n",
    "        color_print(\"Please enter the end month: \", Color.GREEN)\n",
    "        end_month = prompt_user_month()\n",
    "        while True:\n",
    "            color_print(\"Please enter the end year: \", Color.GREEN)\n",
    "            end_year = prompt_user_year()\n",
    "            if end_year >= start_year:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid year. Please enter a year greater than or equal to the start year.\")\n",
    "        \n",
    "    elif option == 12:\n",
    "        color_print(\"12. Exit.\", Color.YELLOW)\n",
    "        color_print(\"Exiting program\", Color.YELLOW)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        color_print(\"Invalid option. Please enter a number between 1 and 12.\", Color.RED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cust_Info(SSN):\n",
    "    from pyspark.sql import SparkSession\n",
    "    try:\n",
    "    # Create a SparkSession\n",
    "        spark = SparkSession.builder.appName(\"check customer detail\").getOrCreate()\n",
    "        # Read the JSON file into a DataFrame\n",
    "        customer_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_custmer.json\")       \n",
    "        # Show the DataFrame\n",
    "        customer_df.createOrReplaceTempView(\"customer\")\n",
    "        query = f\"\"\"\n",
    "            SELECT SSN, \n",
    "            FIRST_NAME, \n",
    "            MIDDLE_NAME, \n",
    "            LAST_NAME, \n",
    "            CREDIT_CARD_NO, \n",
    "            APT_NO, \n",
    "            STREET_NAME, \n",
    "            CUST_CITY, \n",
    "            CUST_STATE, \n",
    "            CUST_ZIP, \n",
    "            CUST_COUNTRY, \n",
    "            CUST_EMAIL, \n",
    "            CUST_PHONE\n",
    "            FROM customer\n",
    "            WHERE RIGHT(SSN, 4) = {SSN}\n",
    "            \"\"\"\n",
    "        result_df = spark.sql(query)\n",
    "        # Show the result DataFrame\n",
    "        result_df.show()\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    finally:\n",
    "    # Stop the SparkSession\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m=====Welcome to the CDW SAPP Credit Card Transaction Management System!=====\u001b[0m\n",
      "\u001b[92mWhat do you want to do? Please choose an option: \u001b[0m\n",
      "\u001b[91m1. Display Customer Information.\u001b[0m\n",
      "\u001b[91m2. Display Branch Information.\u001b[0m\n",
      "\u001b[91m3. Display Credit Card and Transaction Information.\u001b[0m\n",
      "\u001b[91m4. Retrieve customer's transaction in specified zip code for a given month and year.\u001b[0m\n",
      "\u001b[91m5. Sort the transactions by day in descending order.\u001b[0m\n",
      "\u001b[91m6. Display number and total values of transactions for a given type.\u001b[0m\n",
      "\u001b[91m7. Display the total number and total values of transactions for branches in a given state.\u001b[0m\n",
      "\u001b[91m8. Check existing account details of a customer.\u001b[0m\n",
      "\u001b[91m9. Modify existing account details of a customer.\u001b[0m\n",
      "\u001b[91m10. Generate monthly bill.\u001b[0m\n",
      "\u001b[91m11. Display transactions between dates.\u001b[0m\n",
      "\u001b[93m12. Exit.\u001b[0m\n",
      "\u001b[94m==========================================================================\u001b[0m\n",
      "\u001b[93m12. Exit.\u001b[0m\n",
      "\u001b[93mExiting program\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "display_menu()\n",
    "\n",
    "while True:\n",
    "    option = prompt_user_choice()\n",
    "    execute_option(option)\n",
    "    if option == 12:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
