{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Functional Requirements - Load Credit Card Database(SQL)\n",
    "def display_customer_table():\n",
    "    # pyspark code to read customer json file\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import initcap, lower,concat,lit,regexp_replace\n",
    "    try:\n",
    "    # Create a SparkSession\n",
    "        spark = SparkSession.builder.appName(\"Read_Customer_JSON\").getOrCreate()\n",
    "\n",
    "        # Specify the path to the JSON file\n",
    "        json_file_path = r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_custmer.json\"\n",
    "\n",
    "        # Read the JSON file into a DataFrame\n",
    "        df = spark.read.json(json_file_path)\n",
    "        df = df.withColumn(\"CUST_PHONE\", concat(lit(\"337\"), df[\"CUST_PHONE\"]))\n",
    "\n",
    "        formated_df = df.withColumn(\"ADDRESS\", concat(df[\"APT_NO\"], lit(\", \"), df[\"STREET_NAME\"])) \\\n",
    "                        .withColumn(\"CUST_PHONE\", regexp_replace(df[\"CUST_PHONE\"].cast(\"string\"), \"(\\\\d{3})(\\\\d{3})(\\\\d{4})\", \"($1)$2-$3\")) \\\n",
    "                        .withColumn(\"FIRST_NAME\", initcap(\"FIRST_NAME\")) \\\n",
    "                        .withColumn(\"MIDDLE_NAME\", lower(\"MIDDLE_NAME\")) \\\n",
    "                        .withColumn(\"LAST_NAME\", initcap(\"LAST_NAME\"))\n",
    "\n",
    "        # Show the DataFrame\n",
    "        formated_df.select(\"FIRST_NAME\", \"MIDDLE_NAME\", \"LAST_NAME\", \"SSN\", \"CREDIT_CARD_NO\", \"ADDRESS\", \"CUST_CITY\", \"CUST_STATE\", \"CUST_COUNTRY\", \"CUST_ZIP\", \"CUST_PHONE\", \"CUST_EMAIL\", \"LAST_UPDATED\").show(formated_df.count(),truncate=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        # Stop the SparkSession\n",
    "        spark.stop()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_branch_table():\n",
    "    # pyspark to read branch json file\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import initcap, lower,concat,lit,regexp_replace\n",
    "    try:\n",
    "    # Create a SparkSession\n",
    "        spark = SparkSession.builder.appName(\"Read_branch_JSON\").getOrCreate()\n",
    "\n",
    "        # Specify the path to the JSON file\n",
    "        json_file_path = r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_branch.json\"\n",
    "\n",
    "        # Read the JSON file into a DataFrame\n",
    "        df = spark.read.json(json_file_path)\n",
    "        formated_df = df.withColumn(\"BRANCH_PHONE\", regexp_replace(df[\"BRANCH_PHONE\"].cast(\"string\"), \"(\\\\d{3})(\\\\d{3})(\\\\d{4})\", \"($1)$2-$3\"))\n",
    "     \n",
    "    # Show the DataFrame\n",
    "        formated_df.select(\"BRANCH_CODE\",\"BRANCH_NAME\",\"BRANCH_STREET\",\"BRANCH_CITY\",\"BRANCH_STATE\",\"BRANCH_ZIP\",\"BRANCH_PHONE\",\"LAST_UPDATED\").show(df.count(),truncate=False)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    finally:\n",
    "    # Stop the SparkSession\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_credit_table():\n",
    "    # pyspark to read credit json file\n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    # Create a SparkSession\n",
    "    spark = SparkSession.builder.appName(\"Read_credit_JSON\").getOrCreate()\n",
    "\n",
    "    # Specify the path to the JSON file\n",
    "    json_file_path = r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\"\n",
    "\n",
    "    # Read the JSON file into a DataFrame\n",
    "    df = spark.read.json(json_file_path)\n",
    "\n",
    "    try: \n",
    "    # Show the DataFrame\n",
    "        df.select(\"TRANSACTION_ID\",\"DAY\",\"MONTH\",\"YEAR\",\"CREDIT_CARD_NO\",\"CUST_SSN\",\"BRANCH_CODE\",\"TRANSACTION_TYPE\",\"TRANSACTION_VALUE\").show(df.count(),truncate=False)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    # Stop the SparkSession\n",
    "    finally:\n",
    "        spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Data Loading into Database\n",
    "def create_database_in_mysql():\n",
    "    import mysql.connector\n",
    "    import json\n",
    "    try:\n",
    "        conn = mysql.connector.connect(\n",
    "            host=\"localhost\",\n",
    "            user=\"root\",\n",
    "            password=\"password\",\n",
    "        )\n",
    "    \n",
    "    # Execute a SQL query to create the database\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"CREATE DATABASE IF NOT EXISTS `creditcard_capstone`\")\n",
    "        conn.commit()\n",
    "        print(\"Database created successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating database: {e}\")\n",
    "    finally:\n",
    "    # Close the Spark session\n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_in_mysql():\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import initcap, lower,concat,lit,regexp_replace\n",
    "    try:\n",
    "    # Create a Spark session\n",
    "        spark = SparkSession.builder.appName(\"CreateTableInMySQL\").config(\"spark.jars\", r\"E:\\soft\\Spark\\spark-3.5.0-bin-hadoop3\\jars\\mysql-connector-j-8.3.0.jar\").getOrCreate()\n",
    "\n",
    "        # Define the JDBC URL for the MySQL database\n",
    "        jdbc_url = \"jdbc:mysql://localhost:3306/creditcard_capstone\"\n",
    "\n",
    "        df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_custmer.json\")\n",
    "        df2 = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_branch.json\")\n",
    "        df3 = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\")\n",
    "        df = df.withColumn(\"CUST_PHONE\", concat(lit(\"337\"), df[\"CUST_PHONE\"]))\n",
    "        df = df.withColumn(\"CUST_PHONE\", regexp_replace(df[\"CUST_PHONE\"].cast(\"string\"), \"(\\\\d{3})(\\\\d{3})(\\\\d{4})\", \"($1)$2-$3\")) \\\n",
    "                .withColumn(\"FIRST_NAME\", initcap(\"FIRST_NAME\")) \\\n",
    "                .withColumn(\"MIDDLE_NAME\", lower(\"MIDDLE_NAME\")) \\\n",
    "                .withColumn(\"LAST_NAME\", initcap(\"LAST_NAME\"))        \n",
    "                \n",
    "        df2 = df2.withColumn(\"BRANCH_PHONE\", regexp_replace(df2[\"BRANCH_PHONE\"].cast(\"string\"), \"(\\\\d{3})(\\\\d{3})(\\\\d{4})\", \"($1)$2-$3\"))\n",
    "\n",
    "        # Write the DataFrame to the MySQL table \n",
    "        df.write.format(\"jdbc\") \\\n",
    "        .option(\"url\", jdbc_url) \\\n",
    "        .option(\"dbtable\", \"CDW_SAPP_CUSTOMER\") \\\n",
    "        .option(\"user\", \"root\") \\\n",
    "        .option(\"password\", \"password\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "        \n",
    "        \n",
    "        df2.write.format(\"jdbc\") \\\n",
    "        .option(\"url\", jdbc_url) \\\n",
    "        .option(\"dbtable\", \"CDW_SAPP_BRANCH\") \\\n",
    "        .option(\"user\", \"root\") \\\n",
    "        .option(\"password\", \"password\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "        \n",
    "        df3.write.format(\"jdbc\") \\\n",
    "        .option(\"url\", jdbc_url) \\\n",
    "        .option(\"dbtable\", \"CDW_SAPP_CREDIT_CARD\") \\\n",
    "        .option(\"user\", \"root\") \\\n",
    "        .option(\"password\", \"password\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save()\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")\n",
    "        \n",
    "    finally:\n",
    "    # Close the Spark session\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_in_mysql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to modify the tables and set up relationship between table and primary key\n",
    "def modify_tables():\n",
    "    import mysql.connector\n",
    "    import json\n",
    "    try:\n",
    "        conn = mysql.connector.connect(\n",
    "            host=\"localhost\",\n",
    "            user=\"root\",\n",
    "            password=\"password\",\n",
    "            database=\"creditcard_capstone\"\n",
    "        )\n",
    "    \n",
    "        # Execute a SQL query\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "                        ALTER TABLE cdw_sapp_customer \n",
    "                        MODIFY COLUMN CREDIT_CARD_NO VARCHAR(255),\n",
    "                        ADD PRIMARY KEY (SSN),\n",
    "                        ADD INDEX credit_card_index (CREDIT_CARD_NO);\n",
    "                        \"\"\")\n",
    "        conn.commit()\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "                       ALTER TABLE cdw_sapp_branch\n",
    "                       ADD PRIMARY KEY (BRANCH_CODE)\n",
    "                       \"\"\")\n",
    "        conn.commit()\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "                       ALTER TABLE cdw_sapp_credit_card\n",
    "                       MODIFY COLUMN CREDIT_CARD_NO VARCHAR(255),\n",
    "                       ADD PRIMARY KEY (TRANSACTION_ID),\n",
    "                       ADD CONSTRAINT `branch_fk` FOREIGN KEY (`BRANCH_CODE`) REFERENCES `CDW_SAPP_BRANCH` (`BRANCH_CODE`),\n",
    "                       ADD CONSTRAINT `credit_card_fk` FOREIGN KEY (CREDIT_CARD_NO) REFERENCES `CDW_SAPP_CUSTOMER`(CREDIT_CARD_NO)\n",
    "        \"\"\")\n",
    "        conn.commit()    \n",
    "        \n",
    "\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "    # Close the session\n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Transaction Details Module\n",
    "# Prompt the user for a zip code, provide contextual cues for valid input, and verify it is in the correct format.\n",
    "# 1 a. Prompt the user for a zip code\n",
    "def prompt_user_zipcode():\n",
    "    try:\n",
    "        while True:\n",
    "            zipcode = input(\"Enter your zipcode (Enter 5-digit number): \")\n",
    "            if len(zipcode) == 5 and zipcode.isdigit():\n",
    "                return int(zipcode)\n",
    "            else:\n",
    "                print(\"Invalid zipcode. Please enter a 5-digit number.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# b. Prompt the user for a month , year\n",
    "def prompt_user_month():\n",
    "    try:\n",
    "        while True:\n",
    "            month_input = input(\"Enter your month (Enter number 1 - 12): \")\n",
    "            if month_input.isdigit():\n",
    "                if 1 <= int(month_input) <= 12:\n",
    "                    return int(month_input)\n",
    "                else:\n",
    "                    print(\"Invalid month. Please enter a number between 1 and 12.\")\n",
    "            else:\n",
    "                print(\"Invalid Input. Please enter a number between 1 and 12.\")\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "def prompt_user_year():\n",
    "    try:\n",
    "        while True:\n",
    "            year_input = input(\"Enter your year (Enter 4-digit number): \")\n",
    "            if len(year_input) == 4 and year_input.isdigit():\n",
    "                return int(year_input)\n",
    "            else:\n",
    "                print(\"Invalid year. Please enter a 4-digit number.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Query the data using Spark SQL base on user input zipcode, month, year\n",
    "def query_transaction_data_spark(zipcode, month, year):\n",
    "    from pyspark.sql import SparkSession\n",
    "    import json\n",
    "    # Create a Spark session\n",
    "    try:\n",
    "        spark = SparkSession.builder.appName(\"QueryTransactionData\").getOrCreate()\n",
    "\n",
    "        # Load JSON data into DataFrames\n",
    "        branch_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_branch.json\")\n",
    "        transaction_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\")\n",
    "\n",
    "        # Load data from MySQL database using JDBC\n",
    "        jdbc_url = \"jdbc:mysql://localhost:3306/creditcard_capstone\"\n",
    "        properties = {\n",
    "            \"user\": \"root\",\n",
    "            \"password\": \"password\",\n",
    "            \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "        }\n",
    "\n",
    "        # Query the data using Spark SQL\n",
    "        branch_df.createOrReplaceTempView(\"branch\")\n",
    "        transaction_df.createOrReplaceTempView(\"transaction\")\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT branch.BRANCH_CODE, branch.BRANCH_ZIP, transaction.DAY, transaction.MONTH, transaction.YEAR, branch.BRANCH_NAME, branch.BRANCH_STREET, branch.BRANCH_CITY, branch.BRANCH_STATE, branch.BRANCH_PHONE, transaction.CREDIT_CARD_NO, transaction.CUST_SSN, transaction.TRANSACTION_ID, transaction.TRANSACTION_TYPE, transaction.TRANSACTION_VALUE, branch.LAST_UPDATED\n",
    "            FROM branch \n",
    "            JOIN transaction \n",
    "            Using (BRANCH_CODE) \n",
    "            WHERE branch.BRANCH_ZIP = {zipcode} \n",
    "            AND transaction.MONTH = {month} \n",
    "            AND transaction.YEAR = {year}\n",
    "        \"\"\"\n",
    "        result_df = spark.sql(query)\n",
    "\n",
    "        # Show the result DataFrame\n",
    "        result_df.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "    finally:  \n",
    "        # Stop the Spark session\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. Sort the transaction by day\n",
    "def sort_transaction_by_day():\n",
    "    # pyspark to read credit json file\n",
    "    from pyspark.sql import SparkSession\n",
    "    # Create a SparkSession\n",
    "    spark = SparkSession.builder.appName(\"Read_credit_JSON\").getOrCreate()\n",
    "\n",
    "    # Specify the path to the JSON file\n",
    "    json_file_path = r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\"\n",
    "\n",
    "    # Read the JSON file into a DataFrame\n",
    "    df = spark.read.json(json_file_path)\n",
    "\n",
    "    try: \n",
    "    # Show the DataFrame\n",
    "        df.select(\"TRANSACTION_ID\",\"DAY\",\"MONTH\",\"YEAR\",\"CREDIT_CARD_NO\",\"CUST_SSN\",\"BRANCH_CODE\",\"TRANSACTION_TYPE\",\"TRANSACTION_VALUE\").orderBy(\"DAY\", ascending=False).show(df.count(),truncate=False)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    finally:\n",
    "    # Stop the SparkSession\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Use to display number and value of transaction type\n",
    "def transaction_number_value(type):\n",
    "    from pyspark.sql import SparkSession\n",
    "    # Create a SparkSession\n",
    "    spark = SparkSession.builder.appName(\"trasaction_JSON\").getOrCreate()\n",
    "    # Specify the path to the JSON file\n",
    "    json_file_path = r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\"\n",
    "    # Read the JSON file into a DataFrame\n",
    "    df = spark.read.json(json_file_path)\n",
    "\n",
    "    try: \n",
    "    # Show the DataFrame\n",
    "        df.createOrReplaceTempView(\"transaction\")\n",
    "        spark.sql(f\"\"\"SELECT TRANSACTION_TYPE, count(TRANSACTION_TYPE) as Number, round(Sum(TRANSACTION_VALUE),2) as Total \n",
    "                    FROM transaction \n",
    "                    Group By TRANSACTION_TYPE \n",
    "                    HAVING TRANSACTION_TYPE = '{type}'\"\"\").show(df.count(),truncate=False)\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    finally:\n",
    "    # Stop the SparkSession\n",
    "        spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_user_type():\n",
    "    try:\n",
    "        while True:\n",
    "            type = input(\"Enter Transaction Type (Healthcare, Automotive, etc.): \")\n",
    "            if type.isalpha():\n",
    "                return type\n",
    "            else:\n",
    "                print(\"Invalid input. Please enter string only.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Use to display number and total value of transaction branch by given state\n",
    "def transaction_branch_number_value_state(state):\n",
    "    from pyspark.sql import SparkSession\n",
    "    try:\n",
    "    # Create a SparkSession\n",
    "        spark = SparkSession.builder.appName(\"trasaction_JSON\").getOrCreate()\n",
    "        # Read the JSON file into a DataFrame\n",
    "        df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\")\n",
    "        branch_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_branch.json\")\n",
    "\n",
    "        \n",
    "        # Show the DataFrame\n",
    "        df.createOrReplaceTempView(\"transaction\")\n",
    "        branch_df.createOrReplaceTempView(\"branch\")\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT branch.BRANCH_STATE, count(TRANSACTION_TYPE) as Number, round(Sum(TRANSACTION_VALUE),2) as Total\n",
    "            FROM branch \n",
    "            JOIN transaction \n",
    "            Using (BRANCH_CODE)\n",
    "            WHERE branch.BRANCH_STATE = '{state}'\n",
    "            Group By branch.BRANCH_STATE\n",
    "        \"\"\"\n",
    "        \n",
    "        result_df = spark.sql(query)\n",
    "        # Show the result DataFrame\n",
    "        result_df.show()\n",
    "        \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    finally:\n",
    "    # Stop the SparkSession\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_user_state():\n",
    "    try:\n",
    "        while True:\n",
    "            state = input(\"Enter State (LA, CA, etc.): \")\n",
    "            if state.isalpha():\n",
    "                if len(state) == 2:\n",
    "                    return state.upper()\n",
    "                else:\n",
    "                    print(\"Invalid input. Please enter 2-letters for the state only.\")\n",
    "            else:\n",
    "                print(\"Invalid input. Please enter string only.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Customer Details Module\n",
    "# 1 Check existing account details of customer\n",
    "def check_cust_detail(SSN):\n",
    "    from pyspark.sql import SparkSession\n",
    "    try:\n",
    "    # Create a SparkSession\n",
    "        spark = SparkSession.builder.appName(\"check customer detail\").getOrCreate()\n",
    "        # Read the JSON file into a DataFrame\n",
    "        credit_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\")\n",
    "        customer_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_custmer.json\")\n",
    "        branch_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_branch.json\")\n",
    "\n",
    "        \n",
    "        # Show the DataFrame\n",
    "        credit_df.createOrReplaceTempView(\"credit\")\n",
    "        customer_df.createOrReplaceTempView(\"customer\")\n",
    "        branch_df.createOrReplaceTempView(\"branch\")\n",
    "        \n",
    "        query = f\"\"\"\n",
    "            SELECT customer.SSN, \n",
    "            customer.FIRST_NAME, \n",
    "            customer.MIDDLE_NAME, \n",
    "            customer.LAST_NAME, \n",
    "            customer.CREDIT_CARD_NO, \n",
    "            customer.APT_NO, \n",
    "            customer.STREET_NAME, \n",
    "            customer.CUST_CITY, \n",
    "            customer.CUST_STATE, \n",
    "            customer.CUST_ZIP, \n",
    "            customer.CUST_COUNTRY, \n",
    "            customer.CUST_EMAIL, \n",
    "            customer.CUST_PHONE,\n",
    "            branch.BRANCH_NAME,\n",
    "            credit.DAY,\n",
    "            credit.MONTH,\n",
    "            credit.YEAR,\n",
    "            credit.TRANSACTION_TYPE,\n",
    "            credit.TRANSACTION_VALUE\n",
    "            FROM customer\n",
    "            JOIN credit\n",
    "            Using (CREDIT_CARD_NO)\n",
    "            JOIN branch\n",
    "            Using (BRANCH_CODE)\n",
    "            WHERE RIGHT(customer.SSN, 4) = '{SSN}'\n",
    "            ORDER BY credit.YEAR, credit.MONTH, credit.DAY\n",
    "            \"\"\"\n",
    "            \n",
    "        result_df = spark.sql(query)\n",
    "        # Show the result DataFrame\n",
    "        result_df.show()\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    finally:\n",
    "    # Stop the SparkSession\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_user_SSN():\n",
    "    try:\n",
    "        while True:\n",
    "            SSN = input(\"Enter Customer last 4 SSN: \")\n",
    "            if SSN.isnumeric():\n",
    "                if len(SSN) == 4:\n",
    "                    return SSN\n",
    "                else:\n",
    "                    print(\"Invalid input. Please enter 4-digit number only.\")\n",
    "            else:\n",
    "                print(\"Invalid input. Please enter number only.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Modify existing account details of a customer\n",
    "def modify_cust_detail(column, value, SSN):\n",
    "    import mysql.connector\n",
    "    import json\n",
    "    try:\n",
    "        conn = mysql.connector.connect(\n",
    "            host=\"localhost\",\n",
    "            user=\"root\",\n",
    "            password=\"password\",\n",
    "            database=\"creditcard_capstone\"\n",
    "        )\n",
    "    \n",
    "        # Execute a SQL query\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        if check_cust_SSN(SSN):\n",
    "            cursor.execute(f\"\"\"\n",
    "                            UPDATE cdw_sapp_customer\n",
    "                            SET {column} = '{value}'\n",
    "                            WHERE RIGHT(SSN, 4) = '{SSN}';\n",
    "                        \"\"\")\n",
    "            conn.commit()\n",
    "        else:\n",
    "            print(\"Invalid Customer SSN.\")\n",
    "        \n",
    "        query = f\"\"\"\n",
    "                SELECT \n",
    "                FIRST_NAME,\n",
    "                MIDDLE_NAME, \n",
    "                LAST_NAME, \n",
    "                SSN, \n",
    "                CREDIT_CARD_NO, \n",
    "                APT_NO,\n",
    "                STREET_NAME, \n",
    "                CUST_CITY, \n",
    "                CUST_STATE, \n",
    "                CUST_COUNTRY, \n",
    "                CUST_ZIP, \n",
    "                CUST_PHONE, \n",
    "                CUST_EMAIL, \n",
    "                LAST_UPDATED \n",
    "                FROM cdw_sapp_customer\"\"\"\n",
    "                \n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        \n",
    "        data = []\n",
    "        for row in result:\n",
    "            row_dict = {\n",
    "                \"FIRST_NAME\": row[0],\n",
    "                \"MIDDLE_NAME\": row[1],\n",
    "                \"LAST_NAME\": row[2],\n",
    "                \"SSN\":row[3],\n",
    "                \"CREDIT_CARD_NO\":row[4],\n",
    "                \"APT_NO\":row[5],\n",
    "                \"STREET_NAME\":row[6],\n",
    "                \"CUST_CITY\":row[7],\n",
    "                \"CUST_STATE\":row[8],\n",
    "                \"CUST_COUNTRY\":row[9],\n",
    "                \"CUST_ZIP\":row[10],\n",
    "                \"CUST_PHONE\":row[11],\n",
    "                \"CUST_EMAIL\":row[12],\n",
    "                \"LAST_UPDATED\":row[13]\n",
    "            }\n",
    "            data.append(row_dict)\n",
    "    \n",
    "        with open(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_custmer.json\", \"w\") as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cust_SSN(SSN):\n",
    "    import json\n",
    "    try:\n",
    "        with open(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_custmer.json\") as f:\n",
    "            for line in f:\n",
    "                customer_data = json.loads(line)\n",
    "                if str(customer_data[\"SSN\"])[-4:] == str(SSN):\n",
    "                    return True\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Generate monthly bill for a credit card number for a given month and year\n",
    "\n",
    "def check_credit_card(credit_card_no):\n",
    "    import json\n",
    "    try:\n",
    "        with open(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\") as f:\n",
    "            for line in f:\n",
    "                credit_data = json.loads(line)\n",
    "                if str(credit_data[\"CREDIT_CARD_NO\"]) == str(credit_card_no):\n",
    "                    return True\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_monthly_bill(credit_card_no, month, year):\n",
    "    import json\n",
    "    from pyspark.sql import SparkSession\n",
    "    \n",
    "    spark = SparkSession.builder.appName(\"trasaction_JSON\").getOrCreate()\n",
    "    try:\n",
    "        if check_credit_card(credit_card_no):\n",
    "            bill_df = spark.read.json(r\"D:\\CAP 405 Data Analytics - Capstone Project\\cdw_sapp_credit.json\")\n",
    "            bill_df.createOrReplaceTempView(\"bill\")\n",
    "            \n",
    "            query = f\"\"\"\n",
    "                SELECT  CREDIT_CARD_NO, \n",
    "                        MONTH,\n",
    "                        YEAR,\n",
    "                        TRANSACTION_TYPE, \n",
    "                        TRANSACTION_VALUE\n",
    "                        FROM bill\n",
    "                        WHERE CREDIT_CARD_NO = {credit_card_no} \n",
    "                        AND MONTH = {month} \n",
    "                        AND YEAR = {year}              \n",
    "                        ORDER BY YEAR, MONTH, TRANSACTION_TYPE\n",
    "                \"\"\"\n",
    "            bill_df = spark.sql(query)\n",
    "            bill_df.show()\n",
    "            \n",
    "            total = f\"\"\"SELECT  round(sum(TRANSACTION_VALUE),2) as TOTAL_TRANSACTION \n",
    "                                FROM bill \n",
    "                                WHERE CREDIT_CARD_NO = {credit_card_no} \n",
    "                                AND MONTH = {month} \n",
    "                                AND YEAR = {year}\n",
    "                                \n",
    "                                \"\"\"\n",
    "            bill_df = spark.sql(total)\n",
    "            bill_df.show()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_user_credit_card():\n",
    "    try:\n",
    "        while True:\n",
    "            credit_card_no = input(\"Enter your credit card number (16 digits): \")\n",
    "            if len(credit_card_no) == 16 and credit_card_no.isdigit():\n",
    "                return str(credit_card_no)\n",
    "            else:\n",
    "                print(\"Invalid credit card number. Please enter a 16-digit number.\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
